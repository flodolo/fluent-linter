#!/usr/bin/env python3

# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.

from collections import defaultdict
from custom_html_parser import MyHTMLParser
from fluent.syntax import parse, visitor
from fluent.syntax.serializer import FluentSerializer
from pathlib import Path
import argparse
import json
import os
import re
import sys

try:
    from compare_locales import paths
    from compare_locales import parser
except ImportError as e:
    print("FATAL: make sure that dependencies are installed")
    print(e)
    sys.exit(1)


class StringExtraction:
    def __init__(self, l10n_path, search_type, reference_locale):
        """Initialize object."""

        self.translations = defaultdict(dict)

        self.l10n_path = l10n_path
        self.search_type = search_type
        self.reference_locale = reference_locale

    def extractStringsToml(self):
        """Extract strings using TOML configuration."""

        basedir = os.path.dirname(self.l10n_path)
        project_config = paths.TOMLParser().parse(self.l10n_path, env={"l10n_base": ""})
        basedir = os.path.join(basedir, project_config.root)

        reference_cache = {}

        if not project_config.all_locales:
            print("No locales defined in the project configuration.")

        for locale in project_config.all_locales:
            print(f"Extracting strings for locale: {locale}.")
            files = paths.ProjectFiles(locale, [project_config])
            for l10n_file, reference_file, _, _ in files:
                if not os.path.exists(l10n_file):
                    # File not available in localization
                    continue

                if not os.path.exists(reference_file):
                    # File not available in reference
                    continue

                key_path = os.path.relpath(reference_file, basedir)
                try:
                    p = parser.getParser(reference_file)
                except UserWarning:
                    continue
                if key_path not in reference_cache:
                    p.readFile(reference_file)
                    reference_cache[key_path] = set(p.parse().keys())
                    self.translations[self.reference_locale].update(
                        (
                            f"{key_path}:{entity.key}",
                            entity.raw_val,
                        )
                        for entity in p.parse()
                    )

                p.readFile(l10n_file)
                self.translations[locale].update(
                    (
                        f"{key_path}:{entity.key}",
                        entity.raw_val,
                    )
                    for entity in p.parse()
                )
            print(f"  {len(self.translations[locale])} strings extracted")

    def extractLocale(self, locale, base_dir):
        """Extract strings for a locale"""

        # Normalize locale code
        normalized_locale = locale.replace("_", "-")
        for relative_file in self.file_list:
            file_name = os.path.join(base_dir, locale, relative_file)
            if not os.path.exists(file_name):
                continue
            file_extension = os.path.splitext(file_name)[1]

            file_parser = parser.getParser(file_extension)
            file_parser.readFile(file_name)
            try:
                entities = file_parser.parse()
                for entity in entities:
                    # Ignore Junk
                    if isinstance(entity, parser.Junk):
                        continue
                    string_id = f"{relative_file}:{entity}"
                    if file_extension == ".ftl":
                        if entity.raw_val is not None:
                            self.translations[normalized_locale][
                                string_id
                            ] = entity.raw_val
                        # Store attributes
                        for attribute in entity.attributes:
                            attr_string_id = f"{relative_file}:{entity}.{attribute}"
                            self.translations[normalized_locale][
                                attr_string_id
                            ] = attribute.raw_val
                    else:
                        self.translations[normalized_locale][string_id] = entity.raw_val
            except Exception as e:
                print(f"Error parsing file: {file_name}")
                print(e)

        # Remove extra strings from locale
        if self.reference_locale != locale:
            for string_id in list(self.translations[normalized_locale].keys()):
                if string_id not in self.translations[self.reference_locale]:
                    del self.translations[normalized_locale][string_id]

    def extractStringsFolder(self):
        """Extract strings searching for FTL files in folders."""

        base_dir = os.path.dirname(self.l10n_path)
        ref_dir = os.path.join(base_dir, self.reference_locale)

        if not os.path.isdir(ref_dir):
            sys.exit(f"Reference folder {ref_dir} does not exist.")

        # Store the list of FTL files, with paths relative to the source folder
        ref_path = Path(ref_dir)
        files = ref_path.glob("**/*.ftl")
        self.file_list = [os.path.relpath(fp, ref_dir) for fp in files]

        # Get a list of subfolders, assume they're locales
        locales = [
            loc
            for loc in os.listdir(base_dir)
            if os.path.isdir(os.path.join(base_dir, loc))
        ]
        locales.remove(self.reference_locale)
        locales.sort()

        # Extract strings for reference locale
        print(f"Extracting strings for reference locale ({self.reference_locale}).")
        self.extractLocale(self.reference_locale, base_dir)
        print(f"  {len(self.translations[self.reference_locale])} strings extracted")

        # Extract strings for other locales
        for locale in locales:
            print(f"Extracting strings for locale: {locale}")
            self.extractLocale(locale, base_dir)
            # Normalize locale code
            normalized_locale = locale.replace("_", "-")
            print(f"  {len(self.translations[normalized_locale])} strings extracted")

    def extractStrings(self):
        """Extract strings from all locales."""

        if self.search_type == "folder":
            self.extractStringsFolder()
        else:
            self.extractStringsToml()

    def getTranslations(self):
        """Return dictionary with translations"""

        return self.translations


class flattenSelectExpression(visitor.Transformer):
    def visit_SelectExpression(self, node):
        for variant in node.variants:
            if variant.default:
                default_variant = variant
                break

        node.variants = [default_variant]

        return node


class QualityCheck:
    def __init__(self, translations, reference_locale, exceptions_path):

        self.translations = translations
        self.reference_locale = reference_locale
        self.error_messages = defaultdict(list)

        # Load exceptions
        if not exceptions_path:
            self.exceptions = {}
        else:
            try:
                with open(exceptions_path) as f:
                    self.exceptions = json.load(f)
            except Exception as e:
                sys.exit(e)

        self.runChecks()

    def runChecks(self):
        """Check translations for issues"""

        def ignoreString(locale, errorcode, string_id):
            """Check if a string should be ignored"""

            if not self.exceptions:
                return False

            if errorcode == "ellipsis":
                if locale in self.exceptions[errorcode][
                    "excluded_locales"
                ] or string_id in self.exceptions[errorcode]["locales"].get(locale, {}):
                    return True
            else:
                # Ignore excluded strings
                if string_id in self.exceptions[errorcode]["strings"]:
                    return True
                if (
                    locale in self.exceptions[errorcode]["locales"]
                    and string_id in self.exceptions[errorcode]["locales"][locale]
                ):
                    return True

            return False

        datal10n_pattern = re.compile(
            r'data-l10n-name\s*=\s*"([a-zA-Z\-]*)"', re.UNICODE
        )

        placeable_pattern = re.compile(
            r'(?<!\{)\{\s*([\$|-]?[A-Za-z0-9._-]+)(?:[\[(]?[A-Za-z0-9_\-, :"]+[\])])*\s*\}'
        )

        """
        Store specific reference strings for addictional FTL checks:
        - Strings with data-l10n-names
        - Strings with message, terms, or variable references
        """
        reference_data = self.translations[self.reference_locale]
        data_l10n_ids = {}
        placeable_ids = {}
        for string_id, text in reference_data.items():
            file_id, message_id = string_id.split(":")

            if not isinstance(text, str):
                continue

            matches_iterator = datal10n_pattern.finditer(text)
            matches = []
            for m in matches_iterator:
                matches.append(m.group(1))
            if matches:
                # Remove duplicates
                matches = list(set(matches))
                data_l10n_ids[string_id] = sorted(matches)

            matches_iterator = placeable_pattern.finditer(text)
            matches = []
            for m in matches_iterator:
                matches.append(m.group(1))
            if matches:
                # Remove duplicates
                matches = list(set(matches))
                placeable_ids[string_id] = sorted(matches)

        # Store strings with HTML elements
        html_parser = MyHTMLParser()
        html_strings = {}
        for string_id, text in reference_data.items():
            if not isinstance(text, str):
                continue

            if "*[" in text:
                resource = parse(f"temp_id = {text}")
                flattener = flattenSelectExpression()
                serializer = FluentSerializer()
                text = serializer.serialize(flattener.visit(resource))

            html_parser.clear()
            html_parser.feed(text)

            tags = html_parser.get_tags()
            if tags:
                html_strings[string_id] = tags

        for locale, locale_translations in self.translations.items():
            # Ignore reference locale
            if locale == self.reference_locale:
                continue

            # Ignore excluded locales
            if (
                "excluded_locales" in self.exceptions
                and locale in self.exceptions["excluded_locales"]
            ):
                continue

            # General checks on localized strings
            for string_id, translation in locale_translations.items():
                # Ignore excluded strings
                if ignoreString(locale, "general", string_id):
                    continue

                translation = locale_translations[string_id]
                if not isinstance(translation, str):
                    continue

                # Check for pilcrow character
                if "¶" in translation:
                    error_msg = f"Pilcrow character in string ({string_id})"
                    self.error_messages[locale].append(error_msg)

                # Check for stray spaces
                if '{ "' in translation:
                    error_msg = (
                        f"Fluent literal in string ({string_id})\n"
                        f"  Translation: {translation}"
                    )
                    self.error_messages[locale].append(error_msg)

                # Check for the message ID repeated in the translation
                message_id = string_id.split(":")[1]
                pattern = re.compile(re.escape(message_id) + r"\s*=", re.UNICODE)
                if pattern.search(translation):
                    error_msg = f"Message ID is repeated in string ({string_id})"
                    self.error_messages[locale].append(error_msg)

                # Check for 3 dots instead of ellipsis
                if "..." in translation and not ignoreString(
                    locale, "ellipsis", string_id
                ):
                    error_msg = (
                        f"'...' in {string_id}\n" f"  Translation: {translation}"
                    )
                    self.error_messages[locale].append(error_msg)

            # Check for HTML elements mismatch
            html_parser = MyHTMLParser()
            for string_id, ref_tags in html_strings.items():
                # Ignore untranslated strings
                if string_id not in locale_translations:
                    continue

                # Ignore excluded strings
                if ignoreString(locale, "HTML", string_id):
                    continue

                translation = locale_translations[string_id]
                if not isinstance(translation, str):
                    continue
                if "*[" in translation:
                    resource = parse(f"temp_id = {translation}")
                    flattener = flattenSelectExpression()
                    serializer = FluentSerializer()
                    translation = serializer.serialize(flattener.visit(resource))

                html_parser.clear()
                html_parser.feed(translation)
                tags = html_parser.get_tags()

                if sorted(tags) != sorted(ref_tags):
                    error_msg = (
                        f"Mismatched HTML elements in string ({string_id})\n"
                        f"  Translation tags ({len(tags)}): {', '.join(tags)}\n"
                        f"  Reference tags ({len(ref_tags)}): {', '.join(ref_tags)}\n"
                        f"  Translation: {translation}\n"
                        f"  Reference: {self.translations[self.reference_locale][string_id]}"
                    )
                    self.error_messages[locale].append(error_msg)

            # Check data-l10n-names
            for string_id, groups in data_l10n_ids.items():
                if string_id not in locale_translations:
                    continue

                # Ignore excluded strings
                if ignoreString(locale, "data-l10n-names", string_id):
                    continue

                translation = locale_translations[string_id]
                if not isinstance(translation, str):
                    continue
                matches_iterator = datal10n_pattern.finditer(translation)
                matches = []
                for m in matches_iterator:
                    matches.append(m.group(1))
                # Remove duplicates
                matches = list(set(matches))
                if matches:
                    translated_groups = sorted(matches)
                    if translated_groups != groups:
                        # Groups are not matching
                        error_msg = (
                            f"data-l10n-name mismatch in string ({string_id})\n"
                            f"  Translation: {translation}\n"
                            f"  Reference: {self.translations[self.reference_locale][string_id]}"
                        )
                        self.error_messages[locale].append(error_msg)
                else:
                    # There are no data-l10n-name
                    error_msg = (
                        f"data-l10n-name missing in string ({string_id})\n"
                        f"  Translation: {translation}\n"
                        f"  Reference: {self.translations[self.reference_locale][string_id]}"
                    )
                    self.error_messages[locale].append(error_msg)

            # Check placeables
            for string_id, groups in placeable_ids.items():
                if string_id not in locale_translations:
                    continue

                # Ignore excluded strings
                if ignoreString(locale, "placeables", string_id):
                    continue

                translation = locale_translations[string_id]
                if not isinstance(translation, str):
                    continue
                matches_iterator = placeable_pattern.finditer(translation)
                matches = []
                for m in matches_iterator:
                    matches.append(m.group(1))
                # Remove duplicates
                matches = list(set(matches))
                if matches:
                    translated_groups = sorted(matches)
                    if translated_groups != groups:
                        missing_placeables = ", ".join(list(set(groups) - set(matches)))
                        additional_placeables = ", ".join(
                            list(set(matches) - set(groups))
                        )
                        extra_msg = ""
                        extra_msg += (
                            f"  Missing: {missing_placeables}\n"
                            if missing_placeables != ""
                            else ""
                        )
                        extra_msg += (
                            f"  Additional: {additional_placeables}\n"
                            if additional_placeables != ""
                            else ""
                        )
                        # Groups are not matching
                        error_msg = (
                            f"Placeable mismatch in string ({string_id})\n"
                            f"{extra_msg}"
                            f"  Translation: {translation}\n"
                            f"  Reference: {self.translations[self.reference_locale][string_id]}"
                        )
                        self.error_messages[locale].append(error_msg)
                else:
                    # There are no data-l10n-name
                    error_msg = (
                        f"Placeable missing in string ({string_id})\n"
                        "  Missing: " + ", ".join(groups) + "\n"
                        f"  Translation: {translation}\n"
                        f"  Reference: {self.translations[self.reference_locale][string_id]}"
                    )
                    self.error_messages[locale].append(error_msg)

    def printErrors(self):
        """Print error messages"""

        output = []
        total = 0
        if self.error_messages:
            locales = list(self.error_messages.keys())
            locales.sort()

            for locale in locales:
                output.append(
                    f"\nLocale: {locale} ({len(self.error_messages[locale])})"
                )
                total += len(self.error_messages[locale])
                for e in self.error_messages[locale]:
                    output.append(f"\n  {e}")

            output.append(f"\nTotal errors: {total}")
            excluded_locales = self.exceptions.get("excluded_locales", [])
            excluded_locales.sort()
            if excluded_locales:
                excluded_locales = ", ".join(excluded_locales)
                output.append(f"Excluded locales: {excluded_locales}")

        return output


def main():
    # Read command line input parameters
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--toml", nargs="?", dest="toml_path", help="Path to l10n.toml file"
    )
    parser.add_argument(
        "--l10n", nargs="?", dest="l10n_path", help="Path to l10n.toml file"
    )
    parser.add_argument("--ref", dest="reference_code", help="Reference language code")
    parser.add_argument("--dest", dest="dest_file", help="Save output to file")
    parser.add_argument(
        "--exceptions",
        nargs="?",
        dest="exceptions_file",
        help="Path to JSON exceptions file",
    )
    args = parser.parse_args()

    if not args.toml_path and not args.l10n_path:
        sys.exit("It's necessary to specify one between --toml and --l10n parameters")

    search_type = "toml" if args.toml_path else "folder"
    l10n_path = args.toml_path if args.toml_path else args.l10n_path

    extracted_strings = StringExtraction(
        l10n_path=l10n_path,
        search_type=search_type,
        reference_locale=args.reference_code,
    )
    extracted_strings.extractStrings()
    translations = extracted_strings.getTranslations()

    checks = QualityCheck(translations, args.reference_code, args.exceptions_file)
    output = checks.printErrors()
    if output:
        out_file = args.dest_file
        if out_file:
            print(f"Saving output to {out_file}")
            with open(out_file, "w") as f:
                f.write("\n".join(output))
        # Print errors anyway on screen
        print("\n".join(output))
        sys.exit(1)
    else:
        print("No issues found.")


if __name__ == "__main__":
    main()
